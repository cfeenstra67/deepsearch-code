# Models / Experiment log

- `qwen/qwen2.5-vl-32b-instruct` w/ structured outputs
- `openai/gpt-4o` does well, it's reliable

## Run 1
qwen/qwq-32b: 1383.29 ELO (win: 21, tie: 7)
x-ai/grok-3-beta: 1306.73 ELO (win: 13, tie: 12, loss: 3)
openai/o3-mini-high: 1293.98 ELO (win: 13, tie: 13, loss: 2)
google/gemini-2.5-pro-preview-03-25: 1262.55 ELO (win: 11, tie: 14, loss: 3)
anthropic/claude-3.5-sonnet: 1238.12 ELO (loss: 7, win: 12, tie: 9)
anthropic/claude-3.7-sonnet: 1232.17 ELO (win: 12, tie: 7, loss: 9)
openai/gpt-4o-mini: 1206.19 ELO (loss: 11, win: 10, tie: 6, forfeit: 1)
meta-llama/llama-4-maverick: 1201.15 ELO (win: 11, loss: 11, tie: 6)
deepseek/deepseek-chat-v3-0324: 1197.29 ELO (loss: 6, win: 10, tie: 10, forfeit: 2)
openai/gpt-4o: 1176.91 ELO (loss: 11, tie: 10, win: 7)
meta-llama/llama-3.3-70b-instruct: 1152.46 ELO (loss: 15, win: 8, tie: 5)
google/gemini-2.0-flash-001: 1151.19 ELO (win: 5, loss: 11, tie: 12)
mistralai/codestral-2501: 1139.66 ELO (win: 8, tie: 6, loss: 14)
qwen/qwen-turbo: 1118.92 ELO (tie: 5, win: 8, loss: 13, forfeit: 2)
all-hands/openhands-lm-32b-v0.1: 939.39 ELO (error: 28)

## Run 2
qwen/qwq-32b: 1454.08 ELO (win: 31, tie: 10) (avg input=1800.6, output=10833.3 cached_input=0.0 tokens)
anthropic/claude-3.7-sonnet: 1376.46 ELO (win: 25, loss: 6, tie: 10, forfeit: 1) (avg input=2348.3, output=794.0 cached_input=0.0 tokens)
x-ai/grok-3-beta: 1351.89 ELO (win: 26, tie: 14, loss: 1) (avg input=5783.6, output=3604.2 cached_input=0.0 tokens)
google/gemini-2.5-pro-preview-03-25: 1347.15 ELO (win: 24, tie: 17, loss: 1) (avg input=2978.6, output=6701.1 cached_input=0.0 tokens)
openai/o3-mini-high: 1338.62 ELO (win: 25, tie: 12, loss: 5) (avg input=1794.4, output=9957.4 cached_input=0.0 tokens)
anthropic/claude-3.5-sonnet: 1259.74 ELO (win: 20, loss: 11, tie: 10) (avg input=2548.9, output=720.3 cached_input=0.0 tokens)
meta-llama/llama-4-maverick: 1242.77 ELO (win: 19, tie: 10, loss: 13) (avg input=2524.8, output=1127.1 cached_input=0.0 tokens)
deepseek/deepseek-chat-v3-0324: 1239.81 ELO (win: 18, tie: 17, loss: 5, error: 1, forfeit: 1) (avg input=3471.6, output=1735.1 cached_input=0.0 tokens)
openai/gpt-4o-mini: 1231.76 ELO (win: 17, loss: 19, forfeit: 1, tie: 5) (avg input=1975.0, output=709.7 cached_input=146.3 tokens)
mistral/ministral-8b: 1229.23 ELO (win: 18, loss: 17, tie: 3, forfeit: 4) (avg input=2358.6, output=580.1 cached_input=0.0 tokens)
meta-llama/llama-3.3-70b-instruct: 1226.90 ELO (win: 16, loss: 19, tie: 7) (avg input=2073.7, output=673.4 cached_input=0.0 tokens)
mistralai/mistral-small-3.1-24b-instruct: 1222.16 ELO (win: 17, loss: 15, tie: 6, forfeit: 2, error: 2) (avg input=1705.4, output=427.0 cached_input=0.0 tokens)
google/gemini-2.0-flash-001: 1216.22 ELO (win: 17, loss: 13, tie: 10, forfeit: 2) (avg input=2023.2, output=572.2 cached_input=0.0 tokens)
qwen/qwen-turbo: 1213.64 ELO (win: 19, tie: 5, loss: 18) (avg input=1990.2, output=649.3 cached_input=957.0 tokens)
openrouter/optimus-alpha: 1177.45 ELO (win: 18, loss: 15, tie: 9) (avg input=2161.8, output=740.8 cached_input=274.3 tokens)
mistralai/codestral-2501: 1139.96 ELO (win: 16, loss: 22, tie: 4) (avg input=2530.5, output=911.1 cached_input=0.0 tokens)
qwen/qwen2.5-32b-instruct: 1123.49 ELO (forfeit: 3, win: 12, error: 1, loss: 20, tie: 6) (avg input=1916.8, output=480.2 cached_input=0.0 tokens)
openai/gpt-4o: 1121.91 ELO (win: 13, loss: 18, tie: 11) (avg input=1867.5, output=452.1 cached_input=0.0 tokens)
nvidia/llama-3.1-nemotron-ultra-253b-v1:free: 1111.17 ELO (win: 13, error: 21, tie: 4, loss: 2) (avg input=896.7, output=3101.6 cached_input=0.0 tokens)
steelskull/l3.3-electra-r1-70b: 978.92 ELO (win: 5, loss: 6, error: 26, forfeit: 3, tie: 2) (avg input=3959.5, output=4780.9 cached_input=0.0 tokens)
x-ai/grok-3-mini-beta: 908.57 ELO (error: 39, win: 2) (avg input=2313.8, output=780.7 cached_input=0.0 tokens)
allenai/olmo-2-0325-32b-instruct: 888.08 ELO (error: 40, win: 2) (avg input=0.0, output=0.0 cached_input=0.0 tokens)

## Run 3

anthropic/claude-3.7-sonnet:thinking: 1318.41 ELO (win: 14, tie: 9, loss: 2) (avg input=2792.9, output=3854.8 cached_input=0.0 tokens)
qwen/qwq-32b: 1298.46 ELO (win: 12, error: 1, loss: 1, tie: 12) (avg input=2511.4, output=20146.7 cached_input=0.0 tokens)
deepseek/deepseek-r1: 1269.08 ELO (win: 8, tie: 16, error: 1, loss: 1) (avg input=1665.5, output=6722.8 cached_input=0.0 tokens)
google/gemini-2.5-pro-preview-03-25: 1260.18 ELO (win: 9, tie: 14, loss: 2) (avg input=4653.9, output=8507.8 cached_input=0.0 tokens)
anthropic/claude-3.7-sonnet: 1242.78 ELO (win: 11, loss: 8, tie: 7) (avg input=2870.7, output=971.5 cached_input=0.0 tokens)
openai/o3-mini-high: 1238.26 ELO (win: 9, loss: 4, tie: 13) (avg input=2055.9, output=11322.1 cached_input=0.0 tokens)
x-ai/grok-3-beta: 1222.25 ELO (win: 8, tie: 15, loss: 3) (avg input=6344.8, output=3950.5 cached_input=0.0 tokens)
deepseek/deepseek-chat-v3-0324: 1220.88 ELO (win: 8, loss: 2, tie: 14, forfeit: 2) (avg input=2870.9, output=1028.1 cached_input=0.0 tokens)
deepseek/deepseek-r1-distill-qwen-32b: 1189.06 ELO (loss: 7, tie: 14, win: 5) (avg input=2017.7, output=7962.1 cached_input=0.0 tokens)
microsoft/phi-4: 1132.07 ELO (loss: 13, tie: 7, forfeit: 1, win: 5) (avg input=3734.8, output=1270.6 cached_input=0.0 tokens)
google/gemma-3-27b-it: 1128.27 ELO (win: 6, forfeit: 6, loss: 8, tie: 6) (avg input=2745.8, output=609.2 cached_input=0.0 tokens)
anthropic/claude-3.5-sonnet: 1127.54 ELO (win: 4, loss: 12, tie: 10) (avg input=2701.8, output=768.4 cached_input=0.0 tokens)
meta-llama/llama-4-maverick: 1113.10 ELO (loss: 12, tie: 10, win: 4) (avg input=3370.7, output=1392.8 cached_input=0.0 tokens)
ai21/jamba-1.6-large: 1039.66 ELO (error: 5, loss: 13, tie: 5, win: 2, forfeit: 1) (avg input=3131.0, output=707.2 cached_input=0.0 tokens)
