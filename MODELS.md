# Models / Experiment log

- `qwen/qwen2.5-vl-32b-instruct` w/ structured outputs
- `openai/gpt-4o` does well, it's reliable

qwen/qwq-32b: 1383.29 ELO (win: 21, tie: 7)
x-ai/grok-3-beta: 1306.73 ELO (win: 13, tie: 12, loss: 3)
openai/o3-mini-high: 1293.98 ELO (win: 13, tie: 13, loss: 2)
google/gemini-2.5-pro-preview-03-25: 1262.55 ELO (win: 11, tie: 14, loss: 3)
anthropic/claude-3.5-sonnet: 1238.12 ELO (loss: 7, win: 12, tie: 9)
anthropic/claude-3.7-sonnet: 1232.17 ELO (win: 12, tie: 7, loss: 9)
openai/gpt-4o-mini: 1206.19 ELO (loss: 11, win: 10, tie: 6, forfeit: 1)
meta-llama/llama-4-maverick: 1201.15 ELO (win: 11, loss: 11, tie: 6)
deepseek/deepseek-chat-v3-0324: 1197.29 ELO (loss: 6, win: 10, tie: 10, forfeit: 2)
openai/gpt-4o: 1176.91 ELO (loss: 11, tie: 10, win: 7)
meta-llama/llama-3.3-70b-instruct: 1152.46 ELO (loss: 15, win: 8, tie: 5)
google/gemini-2.0-flash-001: 1151.19 ELO (win: 5, loss: 11, tie: 12)
mistralai/codestral-2501: 1139.66 ELO (win: 8, tie: 6, loss: 14)
qwen/qwen-turbo: 1118.92 ELO (tie: 5, win: 8, loss: 13, forfeit: 2)
all-hands/openhands-lm-32b-v0.1: 939.39 ELO (error: 28)
