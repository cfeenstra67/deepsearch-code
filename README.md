# DeepSearch Code

## Overview

`deepsearch-code` is a deepsearch-style agent intended to answer deep, complex questions about code repositories. It's intended to allow answering questions about large, unfamiliar repositories that would otherwise require significant expertise or time commitment to answer.

## Installation & Setup

### Prerequisites

*   **Python:** Requires python 3.13.
*   **Git:** Required for cloning the repository.
*   **Package Manager:** `uv` is recommended. `pip` can also be used.
*   **API Keys:**
    *   An OpenRouter API Key. [OpenRouter Keys](https://openrouter.ai/keys).
    *   (Optional) A GitHub Personal Access Token (PAT) with `repo` scope. [How to create a PAT](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens).

### Installation Steps

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/cfeenstra67/deepsearch-code.git
    cd deepsearch-code
    ```

2.  **Install dependencies:**
    *   **Using `uv` (Recommended):**
        ```bash
        uv sync
        ```
    *   **Using `pip`:**
        ```bash
        pip install .
        ```

3.  **Configure Environment Variables:**
    Set the following environment variables in your shell or `.env` file:
    ```bash
    export GITHUB_TOKEN="your_github_pat" # Optional
    export OPENROUTER_API_KEY="your_openrouter_key"
    ```

## Usage

The main entry point is the `search.py` script. It requires the target repository (in `owner/repo` format) and the question you want to ask.

### Basic Command

```bash
# Using uv
uv run python search.py <owner>/<repo> "Your question about the repository"

# Example
uv run python search.py pulumi/pulumi "How do resource providers work in the Pulumi SDK? Focus on the Python SDK."
```

### Command-Line Arguments

*   `repo` (Required): The target GitHub repository (e.g., `openai/openai-python`).
*   `question` (Required): The question to ask about the repository.
*   `--download`: Force download/update of repository data, even if it exists locally.
*   `--repl`: Start an interactive REPL session after the initial answer.
*   `-o`, `--output <FILENAME>`: Save the full conversation transcript to a file.
*   `-i`, `--input <FILENAME>`: Load and resume a previous conversation from a file.
*   `--researcher-model <MODEL_NAME>`: Specify the OpenRouter model for the researcher agent (default: `google/gemini-2.0-flash-001`).
*   `--manager-model <MODEL_NAME>`: Specify the OpenRouter model for the manager agent (default: `google/gemini-2.5-pro-preview-03-25`).

### Output

The tool prints the final answer generated by the LLM to standard output. It also logs metadata such as elapsed time, LLM costs (if available via OpenRouter headers), and the sequence of tool calls made by the LLM during its reasoning process. If the `-o` flag is used, the complete conversation history is saved to the specified file.

## Configuration

*   **API Keys:** `GITHUB_TOKEN` and `OPENROUTER_API_KEY` must be configured via environment variables.
*   **LLM Models:** The specific LLM models used by the researcher and manager agents can be changed via the `--researcher-model` and `--manager-model` command-line arguments, respectively. Refer to [OpenRouter](https://openrouter.ai/models) for available model identifiers.

## Dependencies

*   Python 3.13+
*   Key libraries include `typer`, `requests`, `sqlite-utils` (for indexing), `anthropic`/`openai` (clients used by OpenRouter wrapper), `tiktoken`.
*   Dependencies are managed using `uv` or `pip` via the `pyproject.toml` file.

## Contributing

Currently, there are no formal contribution guidelines. If you find issues or have suggestions, please open an issue on the GitHub repository page.

## License

This project does not currently have a license specified.

## Contact/Support

For issues, questions, or support, please use the GitHub Issues section of the repository.
